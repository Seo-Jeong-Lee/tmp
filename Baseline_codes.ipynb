{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seo-Jeong-Lee/tmp/blob/main/Baseline_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ab04b1-ceeb-42f9-bd60-b47ab0b27d09",
      "metadata": {
        "id": "72ab04b1-ceeb-42f9-bd60-b47ab0b27d09"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5b9f99a6-eeeb-4286-822e-545cdba4d2b0",
      "metadata": {
        "id": "5b9f99a6-eeeb-4286-822e-545cdba4d2b0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "19588b2c-5a38-48ea-bec9-3fd4b63a085d",
      "metadata": {
        "id": "19588b2c-5a38-48ea-bec9-3fd4b63a085d"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c7e45f-2426-4916-971c-e6ef34658bbe",
      "metadata": {
        "id": "06c7e45f-2426-4916-971c-e6ef34658bbe"
      },
      "source": [
        "## Hyperparameters Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter(하이퍼 파라미터) : 모델링할 때 사용자가 직접 세팅해주는 값\n",
        "\n",
        "예를 들어, learning rate, support-vector-machine(SVM)에서의 c값, KNN에서의 K값 등이 있음"
      ],
      "metadata": {
        "id": "eVJMlnKMUigH"
      },
      "id": "eVJMlnKMUigH"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f863d58c-930e-401e-bae0-0be718fc7ca3",
      "metadata": {
        "id": "f863d58c-930e-401e-bae0-0be718fc7ca3"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE':128,\n",
        "    'EPOCHS':10,\n",
        "    'LEARNING_RATE':2e-3,\n",
        "    'BATCH_SIZE':8,\n",
        "    'SEED':41\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37fde17-5082-4ed7-a003-c7bcbbf65ffb",
      "metadata": {
        "id": "b37fde17-5082-4ed7-a003-c7bcbbf65ffb"
      },
      "source": [
        "## Fix RandomSeed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습한 모델을 Reproduction 하기 위해 Seed 를 고정해야함\n",
        "\n",
        "모델의 Reproduction(복제)이 필요한 경우 : *재현성(Reproducibility)* 유지가 중요\n",
        "\n",
        "1. 수상자가 되어 코드의 정합성을 검증 받게 될 경우,\n",
        "\n",
        "1. 경진대회 참가 도중 팀을 이루어 결과를 공유해야 되는 경우,\n",
        "\n",
        "1. 논문을 작성하여 그 결과를 Reproduction 해야하는 경우 등"
      ],
      "metadata": {
        "id": "nkrJgHdpVxNh"
      },
      "id": "nkrJgHdpVxNh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**재현성(Reproducibility) : 실험을 여러번 했을 때 똑같은 결과를 보장하는 것**"
      ],
      "metadata": {
        "id": "0JvdXnzMYc1u"
      },
      "id": "0JvdXnzMYc1u"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2900cbf8-79f2-496c-a951-b0a74df86aef",
      "metadata": {
        "id": "2900cbf8-79f2-496c-a951-b0a74df86aef"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True             #True 인 경우 cuDNN이 결정적 회선 알고리즘 만 사용하도록 함.\n",
        "    torch.backends.cudnn.benchmark = True                 #True 인 경우 cuDNN이 다중 회선 알고리즘을 벤치마킹하고 가장 빠른 알고리즘을 선택하도록 함.\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**np.random.seed : 난수 발생을 위해서는 적절한 시드(seed)를 난수 발생기에 주어야 함. 만약 시드가 같다면 동일한 난수를 발생시키게 됨**"
      ],
      "metadata": {
        "id": "GOrgqIsHW4oU"
      },
      "id": "GOrgqIsHW4oU"
    },
    {
      "cell_type": "markdown",
      "id": "7aaad7d5-643e-4ccd-ae32-920a9553b630",
      "metadata": {
        "id": "7aaad7d5-643e-4ccd-ae32-920a9553b630"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "iterable : 한 번에 하나의 member를 반환할 수 있는 object.\n",
        "\n",
        "ex) list, str, tuple "
      ],
      "metadata": {
        "id": "AgjwS0G6hVMT"
      },
      "id": "AgjwS0G6hVMT"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "343093ae-587c-4e26-8774-2cab3de75add",
      "metadata": {
        "id": "343093ae-587c-4e26-8774-2cab3de75add"
      },
      "outputs": [],
      "source": [
        "def get_train_data(data_dir):\n",
        "    img_path_list = []\n",
        "    label_list = []\n",
        "    for case_name in os.listdir(data_dir):\n",
        "        current_path = os.path.join(data_dir, case_name)\n",
        "        if os.path.isdir(current_path):                                #os.path.isdir : 디렉토리의 유무를 확인하여 True 혹은 False를 반환하는 함수\n",
        "            # get image path\n",
        "            img_path_list.extend(glob(os.path.join(current_path, 'image', '*.jpg')))\n",
        "            img_path_list.extend(glob(os.path.join(current_path, 'image', '*.png')))      #image path를 img_path_list에 저장하는 과정\n",
        "             \n",
        "            # get label\n",
        "            label_df = pd.read_csv(current_path+'/label.csv')\n",
        "            label_list.extend(label_df['leaf_weight'])                                    #label을 label_list에 저장하는 과정\n",
        "                \n",
        "    return img_path_list, label_list\n",
        "\n",
        "def get_test_data(data_dir):\n",
        "    # get image path\n",
        "    img_path_list = glob(os.path.join(data_dir, 'image', '*.jpg'))\n",
        "    img_path_list.extend(glob(os.path.join(data_dir, 'image', '*.png')))\n",
        "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0]))\n",
        "    return img_path_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extend()함수 : 삽입 대상의 리스트를 풀어서 각각의 엘리먼트로 확장(Extend)해 삽입함. append와 기능적으로는 유사함.\n",
        "\n",
        "```\n",
        ">>> a = [1,2,3]\n",
        ">>> b = [4, 5]\n",
        ">>> a.extend(b)\n",
        ">>> a\n",
        "[1, 2, 3, 4, 5]\n",
        "```"
      ],
      "metadata": {
        "id": "PFMeGuA6xmvV"
      },
      "id": "PFMeGuA6xmvV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "glob() 함수 : 괄호 안에, 인자로 받은 패턴과 이름이 일치하는 모든 파일과 디렉터리의 리스트를 반환함. \n",
        "\n",
        "```\n",
        " from glob import glob\n",
        ">>> glob('*.exe')               # 현재 디렉터리의 .exe 파일\n",
        "['python.exe', 'pythonw.exe']\n",
        ">>> glob('*.txt')               # 현재 디렉터리의 .txt 파일\n",
        "['LICENSE.txt', 'NEWS.txt']\n",
        "```\n",
        "패턴을 그냥 *라고 주면 모든 파일과 디렉터리를 볼 수 있음"
      ],
      "metadata": {
        "id": "Za3nDMQBrQyv"
      },
      "id": "Za3nDMQBrQyv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*img_path_list.extend(glob(os.path.join(current_path, 'image', '*.jpg')))\n",
        "\n",
        "위의 코드를 이해하기 위해 다음의 링크(Answer#2) 참조함\n",
        "https://discuss.dizzycoding.com/python-glob-multiple-filetypes/\n"
      ],
      "metadata": {
        "id": "m3QKYjThiq7f"
      },
      "id": "m3QKYjThiq7f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Competition Data 연동하기****\n",
        "\n",
        "참조 : https://teki.tistory.com/m/29"
      ],
      "metadata": {
        "id": "uyQjB8017WuK"
      },
      "id": "uyQjB8017WuK"
    },
    {
      "cell_type": "code",
      "source": [
        "#구글 드라이브에 open파일 업로드 후 구글드라이브와 Colab연동하기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCnveZ8C6yMA",
        "outputId": "4820f5ee-7718-4b1b-a274-2b49c33c7815"
      },
      "id": "bCnveZ8C6yMA",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZQNOGsQ_63Qj"
      },
      "id": "ZQNOGsQ_63Qj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14655d2b-3c47-409d-9c1e-8de4753950bd",
      "metadata": {
        "id": "14655d2b-3c47-409d-9c1e-8de4753950bd"
      },
      "outputs": [],
      "source": [
        "#위에서 만든 함수 get_train_data와 get_test_data를 이용하여 data 불러오기\n",
        "all_img_path, all_label = get_train_data('./dataset/train')\n",
        "test_img_path = get_test_data('./dataset/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68577959-091a-46cc-9c9b-18e2404f5de6",
      "metadata": {
        "id": "68577959-091a-46cc-9c9b-18e2404f5de6"
      },
      "source": [
        "## Train / Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "31f5a9d4-7af5-466c-b1ac-1480f285dd9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "31f5a9d4-7af5-466c-b1ac-1480f285dd9c",
        "outputId": "c571c025-921c-4f89-8209-54e04fde4c42"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6c8d692d1269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train : Validation = 0.8 : 0.2 Split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_img_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_img_path' is not defined"
          ]
        }
      ],
      "source": [
        "# Train : Validation = 0.8 : 0.2 Split\n",
        "train_len = int(len(all_img_path)*0.8)\n",
        "\n",
        "train_img_path = all_img_path[:train_len]\n",
        "train_label = all_label[:train_len]\n",
        "\n",
        "vali_img_path = all_img_path[train_len:]\n",
        "vali_label = all_label[train_len:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af7e345-7445-4717-909c-2a2e0a4e8993",
      "metadata": {
        "id": "5af7e345-7445-4717-909c-2a2e0a4e8993"
      },
      "source": [
        "## CustomDataset : Dataset을 상속 받아 Cusstom Dataset class 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "참조 : \n",
        "\n",
        "https://sanghyu.tistory.com/90\n",
        "\n",
        "https://data-panic.tistory.com/21\n",
        "\n",
        "https://didu-story.tistory.com/85\n",
        "\n",
        "https://blog.promedius.ai/pytorch_dataloader_1/\n"
      ],
      "metadata": {
        "id": "ZzTmqrn03DAj"
      },
      "id": "ZzTmqrn03DAj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b24583-9c39-47df-84b3-f606ffdf5852",
      "metadata": {
        "id": "10b24583-9c39-47df-84b3-f606ffdf5852"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):   #부모클래스가 Dataset, 자식클래스는 CustomDataset이다. 자식클래스는 부모클래스로부터 상속받는다.\n",
        "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):     #생성자 부분. 속성을 초기화하는 목적으로 사용. \n",
        "        self.transforms = transforms                                                     #메서드를 호출할 때 self 자리는 비워놓는다.(입력하지 않는다)\n",
        "        self.train_mode = train_mode                                                     #이 클래스의 속성은 4개이다.(transforms, train_mode, img_path_list, label_list)          \n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "\n",
        "    def __getitem__(self, index):                                                         \n",
        "        img_path = self.img_path_list[index]   #앞서 만든 리스트(img_path_list)의 인덱스값을 참조해 해당 이미지를 연 다음, (4줄 아래와 이어짐)\n",
        "        # Get image data\n",
        "        image = cv2.imread(img_path)        \n",
        "        if self.transforms is not None:     #transforms 가 None이 아닌 경우 : transforms를 실행할 경우\n",
        "            image = self.transforms(image)  #tensor 자료형으로 바꾸어 이미지 전처리를 실행하는 구조이다.\n",
        "\n",
        "        if self.train_mode: #train_mode = True라면,\n",
        "            label = self.label_list[index]    #앞서 만든 리스트(label_list)의 인덱스값을 참조해 해당 label을 연다\n",
        "            return image, label\n",
        "        else:               #train_mode = False라면, 해당 이미지만을 연다\n",
        "            return image\n",
        "    \n",
        "    def __len__(self):      #학습 데이터의 갯수를 반환하는 역할을 한다\n",
        "        return len(self.img_path_list) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torchvision.transforms**를 이용하는 데이터 전처리 \n",
        "\n",
        ": transforms에 속한 함수들을 Compose를 통해 묶어서 한번에 처리할 수 있다.\n",
        "\n",
        "-> transforms의 여러 메서드들은 다음의 링크를 참조함:\n",
        "\n",
        "https://mhko411.tistory.com/157"
      ],
      "metadata": {
        "id": "ZqEc-nU_cCm-"
      },
      "id": "ZqEc-nU_cCm-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352f1a75-a858-4a10-bccf-c56afce6a2a3",
      "metadata": {
        "id": "352f1a75-a858-4a10-bccf-c56afce6a2a3"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "                    transforms.ToTensor(),                                                 #PIL 이미지 또는 numpy.ndarray 형식의 이미지를 tensor 형식으로 변환한다.(0~255->0~1) \n",
        "                    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),                 #주어진 PIL 이미지를 입력한 size로 크기 조정을 한다.\n",
        "                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))        #주어진 이미지를 mean, std의 값을 통해 정규화 한다.\n",
        "                    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*주의할 점 : 항상 transforms.Normalize는 transforms.ToTensor 뒤에 와야한다*\n",
        "\n",
        "참조 : https://89douner.tistory.com/299"
      ],
      "metadata": {
        "id": "GUZ-lD_0bnHP"
      },
      "id": "GUZ-lD_0bnHP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17aa1756-4b35-4a48-aa5d-f5b6e8524f55",
      "metadata": {
        "id": "17aa1756-4b35-4a48-aa5d-f5b6e8524f55"
      },
      "outputs": [],
      "source": [
        "# Get Dataloader\n",
        "train_dataset = CustomDataset(train_img_path, train_label, train_mode=True, transforms=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
        "\n",
        "vali_dataset = CustomDataset(vali_img_path, vali_label, train_mode=True, transforms=test_transform)\n",
        "vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader는 일반적으로 샘플들을 mini batch로 전달하고, \n",
        "\n",
        "매 epoch마다 데이터를 다시 섞어서 과적합(overfit)을 방지하고 \n",
        "\n",
        "multiprocessing(CPU_WORKER =>num_workers 관련)을 사용하여 데이터 검색 속도를 높이려고 한다.\n",
        "\n",
        "(num_workers 참조 링크 : \n",
        "\n",
        "https://m.blog.naver.com/qbxlvnf11/221728476511\n",
        "\n",
        "https://jybaek.tistory.com/799)"
      ],
      "metadata": {
        "id": "-LRjTemLgUlX"
      },
      "id": "-LRjTemLgUlX"
    },
    {
      "cell_type": "markdown",
      "id": "6e04e913-7a5c-4e20-a9ad-2ad1089f16dd",
      "metadata": {
        "id": "6e04e913-7a5c-4e20-a9ad-2ad1089f16dd"
      },
      "source": [
        "## Define Model Architecture (CNN 모델 만들기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7188a84b-6f8a-4f43-8235-6208835b1d90",
      "metadata": {
        "id": "7188a84b-6f8a-4f43-8235-6208835b1d90"
      },
      "outputs": [],
      "source": [
        "class CNNRegressor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNRegressor, self).__init__()\n",
        "        self.layer1 = torch.nn.Sequential(                           \n",
        "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.regressor = nn.Linear(3136,1)         #pytoch에서의 선형 회귀함수로, (입력의 차원, 출력의 차원)을 인수로 받음.\n",
        "\n",
        "\n",
        "    def forward(self, x):   #순전파 알고리즘(역전파 X)\n",
        "        # Simple CNN Model (Batch, 3, 128, 128 -> Batch, 64, 7, 7)\n",
        "        # (Batch, 3, 128, 128)\n",
        "        x = self.layer1(x)\n",
        "        # (Batch, 8, 64, 64)\n",
        "        x = self.layer2(x)\n",
        "        # (Batch, 16, 32, 32)\n",
        "        x = self.layer3(x)\n",
        "        # (Batch, 32, 16, 16)\n",
        "        x = self.layer4(x)\n",
        "        # (Batch, 64, 7, 7) -> Flatten (Batch, 64*7*7(=3136))\n",
        "        x = torch.flatten(x, start_dim=1)     \n",
        "        # Regressor (Batch, 3136) -> (Batch, 1)\n",
        "        out = self.regressor(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.Sequential** :\n",
        "forward() 함수의 형태를 Layer 형태로 나타낼 수 있게 하여 보다 가독성이 뛰어나게 코드 작성할 수 있도록 함\n",
        "\n",
        "\n",
        "+Layer가 복잡해질수록 nn.Sequential의 효과가 뛰어남.\n",
        "\n",
        "참조 : https://dororongju.tistory.com/147"
      ],
      "metadata": {
        "id": "19_a8Xibm4un"
      },
      "id": "19_a8Xibm4un"
    },
    {
      "cell_type": "markdown",
      "id": "629903e0-7438-4494-bef0-1db1db28f4b2",
      "metadata": {
        "id": "629903e0-7438-4494-bef0-1db1db28f4b2"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e462f95f-cf3c-4b78-84b7-ef50e4690c1b",
      "metadata": {
        "id": "e462f95f-cf3c-4b78-84b7-ef50e4690c1b"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, vali_loader, scheduler, device):\n",
        "    model.to(device)        #.to(device)를 통해 GPU 연산을 할 수 있게 한다.\n",
        "    # Loss Function\n",
        "    criterion = nn.L1Loss().to(device)       #loss함수 criterion을 L1Loss로 지정한다./.to(device)를 이용하여 GPU 연산한다.\n",
        "    best_mae = 9999\n",
        "    \n",
        "    for epoch in range(1,CFG[\"EPOCHS\"]+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        for img, label in tqdm(iter(train_loader)):\n",
        "            img, label = img.float().to(device), label.float().to(device)\n",
        "            \n",
        "            optimizer.zero_grad()       #gradient를 0으로 초기화하기.기본적으로 gradient는 더해지기 때문에 중복 계산을 막기 위해 반복할 때(가중치 갱신 때)마다 0으로 설정함.\n",
        "\n",
        "            # Data -> Model -> Output\n",
        "            logit = model(img)\n",
        "            # Calc loss\n",
        "            loss = criterion(logit.squeeze(1), label)     #squeeze 함수 설명 아래 쪽에..\n",
        "\n",
        "            # backpropagation\n",
        "            loss.backward()     #loss 함수를 미분하여 gradient 계산\n",
        "            optimizer.step()    #바로 윗 단계에서 수집된 gradient로 가중치(W,b) 최적화(업데이트 혹은 갱신)하기\n",
        "\n",
        "            train_loss.append(loss.item())   #모델에서 계산된 loss 가 있다면, loss.item()을 통해 loss의 스칼라 값을 가져올 수 있음.\n",
        "            \n",
        "        if scheduler is not None:  #scheduler : If you don't call it, the learning rate won't be changed and stays at the initial value. 즉 learning rate를 조정하는 역할.\n",
        "            scheduler.step()\n",
        "            \n",
        "        # Evaluation Validation set\n",
        "        vali_mae = validation(model, vali_loader, criterion, device)\n",
        "        \n",
        "        print(f'Epoch [{epoch}] Train MAE : [{np.mean(train_loss):.5f}] Validation MAE : [{vali_mae:.5f}]\\n')\n",
        "        \n",
        "        # Model Saved\n",
        "        if best_mae > vali_mae:\n",
        "            best_mae = vali_mae\n",
        "            torch.save(model.state_dict(), './saved/best_model.pth')\n",
        "            print('Model Saved.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**squeeze() 함수 추가 설명**\n",
        "\n",
        "(A x B x 1 x C x 1) 형태의 텐서에서\n",
        "\n",
        "차원이 1인 부분을 제거하여 (A x B x C) 형태로 만들어 준다.\n",
        "\n",
        "또한, 원하는 dimension 위치를 따로 선택하면, 해당 위치의 1만 삭제가 가능하다. *ex) logit.squeeze(dim=1)*\n",
        "\n",
        "단, 해당 차원 위치의 size가 1이 아니라면, 삭제가 불가능하다."
      ],
      "metadata": {
        "id": "jEseJXN03Fby"
      },
      "id": "jEseJXN03Fby"
    },
    {
      "cell_type": "markdown",
      "source": [
        "참조 : \n",
        "\n",
        "https://wikidocs.net/55409\n",
        "\n",
        "https://jimmy-ai.tistory.com/110 (pytorch squeeze 함수 정리)"
      ],
      "metadata": {
        "id": "aDJaoujCuISP"
      },
      "id": "aDJaoujCuISP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38eb2190-6eac-4398-85ac-4f94f8fb8b97",
      "metadata": {
        "id": "38eb2190-6eac-4398-85ac-4f94f8fb8b97"
      },
      "outputs": [],
      "source": [
        "def validation(model, vali_loader, criterion, device):\n",
        "    model.eval()  # Evaluation. 모델의 모든 Layer가 Evaluation-mode에 들어가게 해줌\n",
        "    vali_loss = []\n",
        "    with torch.no_grad():     #gradient를 계산해주는 Engiene을 비활성화 시켜 메모리를 줄여주고, 연산속도를 증가시킴.\n",
        "        for img, label in tqdm(iter(vali_loader)):       #tqdm 라이브러리 : for 문의 in 구문을 tqdm으로 감싸기만 하면->작업진행률 바가 시각화 되어 나타남.\n",
        "            img, label = img.float().to(device), label.float().to(device)\n",
        "\n",
        "            logit = model(img)\n",
        "            loss = criterion(logit.squeeze(1), label)   #위에서 선언했듯이 criterion=L1loss함수이다.\n",
        "            \n",
        "            vali_loss.append(loss.item())     #모델에서 계산된 loss 가 있다면, loss.item()을 통해 loss의 스칼라 값을 가져올 수 있음.\n",
        "\n",
        "    vali_mae_loss = np.mean(vali_loss)\n",
        "    return vali_mae_loss  #mae = mean absolute error(평균 절대 오차). mse와 거의 유사."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "참조 : https://yuevelyne.tistory.com/10"
      ],
      "metadata": {
        "id": "-j0K4ysDv7Qp"
      },
      "id": "-j0K4ysDv7Qp"
    },
    {
      "cell_type": "markdown",
      "id": "c87bb28e-f574-43a0-a242-1ba3d34d0656",
      "metadata": {
        "id": "c87bb28e-f574-43a0-a242-1ba3d34d0656"
      },
      "source": [
        "## Run!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379342b0-211f-4de4-8ec3-8c16d76e37ef",
      "metadata": {
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "6fa4ccb221134b8b80f03ef047f352aa",
            "c153475fcb8c47bd9787cb28cf50ad79",
            "20a7e18f2f774d3a83047386ce9259da",
            "730582ced39d4d548951e0933527852a",
            "6663f4ab7114446795f5705e6ab4d383",
            "ef4ef4af8d32491bb6b56b5e3a43bdff",
            "6a79785ef168447eb26bd48a0ed51389",
            "d1a30f043c7e4a548af3b4a57a0776b1",
            "03bde1f93727417aa115258a98f1122f",
            "0a1c1056aed7402288efd1a0e33c5f03",
            "9796dbf1b60b471297c1baa42c6f75c5",
            "bd6c5545863f4076ae72f89af80363d5",
            "a0fed13b93f94572950a9c41b3f5b19f",
            "9f9aa0777b724744bc802f7bc87f8cc3",
            "d566685d4b0449e8b19d50e974a25579",
            "364c66489ac6448086c1a99ee701deb0",
            "6d892e3908034414939c92bf46edf71f",
            "b2fff6328363462291e15f3c960c0c3a",
            "895c646d5c5b437aa8f94ee78e0b22b3",
            "d19aaa1a694d4747ada4521610c65052"
          ]
        },
        "id": "379342b0-211f-4de4-8ec3-8c16d76e37ef",
        "outputId": "038f6d42-258b-4244-e18e-c98c28ee5704"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fa4ccb221134b8b80f03ef047f352aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c153475fcb8c47bd9787cb28cf50ad79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1] Train MAE : [63.01995] Validation MAE : [56.88789]\n",
            "\n",
            "Model Saved.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20a7e18f2f774d3a83047386ce9259da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "730582ced39d4d548951e0933527852a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2] Train MAE : [43.94474] Validation MAE : [24.88520]\n",
            "\n",
            "Model Saved.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6663f4ab7114446795f5705e6ab4d383",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef4ef4af8d32491bb6b56b5e3a43bdff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3] Train MAE : [38.27210] Validation MAE : [12.71966]\n",
            "\n",
            "Model Saved.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a79785ef168447eb26bd48a0ed51389",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1a30f043c7e4a548af3b4a57a0776b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4] Train MAE : [21.06482] Validation MAE : [18.58724]\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03bde1f93727417aa115258a98f1122f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a1c1056aed7402288efd1a0e33c5f03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5] Train MAE : [18.39487] Validation MAE : [54.58783]\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9796dbf1b60b471297c1baa42c6f75c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd6c5545863f4076ae72f89af80363d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6] Train MAE : [18.94871] Validation MAE : [43.81117]\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0fed13b93f94572950a9c41b3f5b19f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f9aa0777b724744bc802f7bc87f8cc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7] Train MAE : [17.14110] Validation MAE : [19.56329]\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d566685d4b0449e8b19d50e974a25579",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "364c66489ac6448086c1a99ee701deb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8] Train MAE : [15.65310] Validation MAE : [43.01975]\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d892e3908034414939c92bf46edf71f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2fff6328363462291e15f3c960c0c3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9] Train MAE : [15.70300] Validation MAE : [36.53123]\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "895c646d5c5b437aa8f94ee78e0b22b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d19aaa1a694d4747ada4521610c65052",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10] Train MAE : [14.46853] Validation MAE : [16.36535]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = CNNRegressor().to(device)  #GPU를 사용한다\n",
        "\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])  #SGD optimizer를 사용한다\n",
        "scheduler = None     #initial learning rate를 유지하여 사용한다\n",
        "\n",
        "train(model, optimizer, train_loader, vali_loader, scheduler, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "660aa9ae-6aaf-47fc-8ed4-eca154466544",
      "metadata": {
        "id": "660aa9ae-6aaf-47fc-8ed4-eca154466544"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e55d732-3cd1-4034-a568-8cce6f29f993",
      "metadata": {
        "id": "0e55d732-3cd1-4034-a568-8cce6f29f993"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_loader, device):\n",
        "    model.eval()\n",
        "    model_pred = []\n",
        "    with torch.no_grad():\n",
        "        for img in tqdm(iter(test_loader)):\n",
        "            img = img.float().to(device)\n",
        "\n",
        "            pred_logit = model(img)\n",
        "            pred_logit = pred_logit.squeeze(1).detach().cpu()\n",
        "\n",
        "            model_pred.extend(pred_logit.tolist())\n",
        "    return model_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1ee67e0-daba-4471-8f97-c5506dbfc990",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1674334ee3724eea9155d91180fb52fd"
          ]
        },
        "id": "b1ee67e0-daba-4471-8f97-c5506dbfc990",
        "outputId": "ef90e0b2-6a4a-49fb-e758-8c2d86945960"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1674334ee3724eea9155d91180fb52fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/58 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_dataset = CustomDataset(test_img_path, None, train_mode=False, transforms=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "# Validation Score가 가장 뛰어난 모델을 불러옵니다.\n",
        "checkpoint = torch.load('./saved/best_model.pth')\n",
        "model = CNNRegressor().to(device)\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "# Inference\n",
        "preds = predict(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb00479c-a650-4b38-bd21-d4c1018ba57e",
      "metadata": {
        "id": "eb00479c-a650-4b38-bd21-d4c1018ba57e"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d169965e-8066-464e-b755-9a2db0d018b6",
      "metadata": {
        "id": "d169965e-8066-464e-b755-9a2db0d018b6"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('./sample_submission.csv')\n",
        "submission['leaf_weight'] = preds\n",
        "submission.to_csv('./submit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "name": "Baseline_codes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}