{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e0JV98NrF7X"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFW0Ue-UrF7b"
      },
      "source": [
        "# Deep learning for text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzz4RfsMrF7c"
      },
      "source": [
        "## Natural-language processing: The bird's eye view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFfLbX-QrF7d"
      },
      "source": [
        "## Preparing text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1zX5rWprF7d"
      },
      "source": [
        "### Text standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeQe_yHCrF7e"
      },
      "source": [
        "### Text splitting (tokenization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0gVBUYYrF7f"
      },
      "source": [
        "### Vocabulary indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCMq0wywrF7g"
      },
      "source": [
        "### Using the TextVectorization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e6mF49Z0rF7g"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "class Vectorizer:\n",
        "    def standardize(self, text):\n",
        "        text = text.lower()\n",
        "        return \"\".join(char for char in text if char not in string.punctuation)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        text = self.standardize(text)\n",
        "        return text.split()\n",
        "\n",
        "    def make_vocabulary(self, dataset):\n",
        "        self.vocabulary = {\"\": 0, \"[UNK]\": 1}      #Vectorize.vocabulary에 vocab이 저장됨\n",
        "        for text in dataset:\n",
        "            text = self.standardize(text)\n",
        "            tokens = self.tokenize(text)\n",
        "            for token in tokens:\n",
        "                if token not in self.vocabulary:\n",
        "                    self.vocabulary[token] = len(self.vocabulary)\n",
        "        self.inverse_vocabulary = dict(\n",
        "            (v, k) for k, v in self.vocabulary.items())\n",
        "\n",
        "    def encode(self, text):\n",
        "        text = self.standardize(text)\n",
        "        tokens = self.tokenize(text)\n",
        "        return [self.vocabulary.get(token, 1) for token in tokens]\n",
        "\n",
        "    def decode(self, int_sequence):\n",
        "        return \" \".join(\n",
        "            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n",
        "\n",
        "vectorizer = Vectorizer()\n",
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "vectorizer.make_vocabulary(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.vocabulary"
      ],
      "metadata": {
        "id": "j4A4_5n7rzjm",
        "outputId": "589dbf28-52c4-4451-ee0a-6cda177b7ba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " '[UNK]': 1,\n",
              " 'a': 9,\n",
              " 'again': 6,\n",
              " 'and': 7,\n",
              " 'blooms': 11,\n",
              " 'erase': 4,\n",
              " 'i': 2,\n",
              " 'poppy': 10,\n",
              " 'rewrite': 5,\n",
              " 'then': 8,\n",
              " 'write': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn3s37m3rF7i",
        "outputId": "22b1e12f-0b66-4a17-8a54-5d3793490e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 5, 7, 1, 5, 6]\n"
          ]
        }
      ],
      "source": [
        "#인코딩\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = vectorizer.encode(test_sentence)\n",
        "print(encoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRXlGPeZrF7j",
        "outputId": "de13e8a2-0de7-4591-d6c7-b82401899af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "#디코딩\n",
        "decoded_sentence = vectorizer.decode(encoded_sentence)\n",
        "print(decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jlbe6887rF7j"
      },
      "outputs": [],
      "source": [
        "#끈데 이미 이 함수가 keras에 있지!!\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0wT7N-L9rF7j"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "    lowercase_string = tf.strings.lower(string_tensor)       #tf함수를 이용한다는 것을 알아두세요. (tf.strings)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")  #문장부호 제거하기\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "    return tf.strings.split(string_tensor)\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn,\n",
        "    split=custom_split_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ox3FIGMvrF7k"
      },
      "outputs": [],
      "source": [
        "dataset = [\n",
        "    \"I write, erase, rewrite\",\n",
        "    \"Erase again, and then\",\n",
        "    \"A poppy blooms.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnINBtjbrF7k"
      },
      "source": [
        "**Displaying the vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIfTxS-3rF7k",
        "outputId": "20e0eda4-8ed7-47c0-86b1-9e376fc58072"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'erase',\n",
              " 'write',\n",
              " 'then',\n",
              " 'rewrite',\n",
              " 'poppy',\n",
              " 'i',\n",
              " 'blooms',\n",
              " 'and',\n",
              " 'again',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "text_vectorization.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFOSZYzFrF7l",
        "outputId": "c6aeb55c-2b63-45ea-e898-594875a2e552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LreSYkdPrF7l",
        "outputId": "4e4fc67f-32b0-4f51-f95c-fdde9e101d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n"
          ]
        }
      ],
      "source": [
        "inverse_vocab = dict(enumerate(vocabulary))     #enumerate함수 : 열거 함수 -> text_vectorization.get_vocabulary()로 얻은 것들을 딕셔너리에 enumerate하여 저장함.\n",
        "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
        "print(decoded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q3MPqzFrF7l"
      },
      "source": [
        "## Two approaches for representing groups of words: Sets and sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_vSOklRrF7l"
      },
      "source": [
        "### Preparing the IMDB movie reviews data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp2xyFfDrF7l",
        "outputId": "58719352-35dd-415c-c0d3-d8c699a90b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  13.9M      0  0:00:05  0:00:05 --:--:-- 19.0M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox1ZBy72rF7m",
        "outputId": "bb22c4b4-9034-46a7-998f-eaa5cc883215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'aclImdb/train/unsup': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZkyXC34rF7m",
        "outputId": "ea20b049-ecf2-4dac-f252-c534bf20183f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: aclImdb/train/pos/4077_10.txt: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('aclImdb')"
      ],
      "metadata": {
        "id": "rNtVS_bStEYC",
        "outputId": "18ebf4f3-e269-4be2-c91f-cbd7098bec41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'README', 'val', 'imdbEr.txt', 'imdb.vocab', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "aUvgtlGMrF7m",
        "outputId": "e66038e3-7a63-4cc9-97c9-12a3c9d66617"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2c1d89696506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train\"\u001b[0m     \u001b[0;31m#이름이 'train'인 dir생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"neg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'aclImdb/val/neg'"
          ]
        }
      ],
      "source": [
        "#이건 여러번 하면 안됨. 이미 있는데 계속 누르면 오류나겠지. 그래서 오류난거임. 다시 실행하면 괜찮을거야.\n",
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"         #이름이 'val'인 dir생성\n",
        "train_dir = base_dir / \"train\"     #이름이 'train'인 dir생성\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('aclImdb')"
      ],
      "metadata": {
        "id": "hjkwfZ2CtO0P",
        "outputId": "c3981d66-1a98-4f05-e9e0-f5da742794ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'README', 'val', 'imdbEr.txt', 'imdb.vocab', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2juIs0igrF7m",
        "outputId": "3b1ac207-8429-4cac-8c0b-78b6e6f6136d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(             #load the file to our datasets\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjg6MbSSrF7m"
      },
      "source": [
        "**Displaying the shapes and dtypes of the first batch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOOGvr_2rF7m",
        "outputId": "95546f77-2f17-4af8-e542-468caa24b8bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"A fantastic Arabian adventure. A former king, Ahmad, and his best friend, the thief Abu (played by Sabu of Black Narcissus) search for Ahmad's love interest, who has been stolen by the new king, Jaffar (Conrad Veidt). There's hardly a down moment here. It's always inventing new adventures for the heroes. Personally, I found Ahmad and his princess a little boring (there's no need to ask why John Justin, who plays Ahmad, is listed fourth in the credits). Conrad Veidt, always a fun actor, makes a great villain, and Sabu is a lot of fun as the prince of thieves, who at one point finds a genie in a bottle. I also really loved Miles Malleson as the Sultan of Basra, the father of the princess. He collects amazing toys from around the world. Jaffar bribes him for his daughter's hand with a mechanical flying horse. This probably would count as one of the great children's films of all time, but the special effects are horribly dated nowadays. Kids will certainly deride the superimposed images when Abu and the genie are on screen together. And the scene with the giant spider looks especially awful. Although most of the younger generation probably thinks that King Kong looks bad at this point in time, Willis O'Brien's stop-motion animation is a thousand times better than a puppet on a string that doesn't even look remotely like a spider. 8/10.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)         #모두 string 자료형이여서 Normalization 필요함\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI4xhoBsrF7n"
      },
      "source": [
        "### Processing words as a set: The bag-of-words approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAScHRM4rF7n"
      },
      "source": [
        "#### Single words (unigrams) with binary encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h-s8RpurF7n"
      },
      "source": [
        "**Preprocessing our datasets with a `TextVectorization` layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P2h1qZVPrF7n"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)    #train_ds(dataset)에는 x,y가 둘다 있는데 그 중 x의 값만을 호출함\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),     #input은 x,y -> output은 x에 vectorization함수를 적용한 것과 y\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,y in train_ds.take(1):\n",
        "    print(i)\n",
        "    print(y)"
      ],
      "metadata": {
        "id": "wP4Z6Y4hxkPB",
        "outputId": "b15c0621-57d3-48b5-a90b-e706b7e646ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"Modern, original, romantic story.<br /><br />Very good acting of both Nicole Kidman and Ben Chaplin.<br /><br />Miss Kidman does a nice job in imitating a Russian accent. Ben Chaplin is also good as the shy, dull clerk. For the men (and some women) : miss Kidman looks fantastic and is very sympathetic. I forgot what a gorgeous woman she is. It's not hard to imagine that John falls in love with her. Some unexpected turns in the story are good for the suspense. Although I hoped for a happy ending, the last part of the movie was quite a surprise for me. <br /><br />Conclusion : good movie. <br /><br />Les Pays-Bas : huit points.\"\n",
            " b\"This is simply the funniest movie I've seen in a long time. The bad acting, bad script, bad scenery, bad costumes, bad camera work and bad special effects are so stupid that you find yourself reeling with laughter.<br /><br />So it's not gonna win an Oscar but if you've got beer and friends round then you can't go wrong.\"\n",
            " b\"Who actually created this piece of crap this is the worst movie i have ever seen in my life it is such a waste of time and money. I hate it how they create low budget sequels featuring D-Lister actors and a storyline so similar to the 1st one.<br /><br />I found this movie in the bargain bin sitting right next to Wild Things 2 and Death To The Supermodels for $2.99 what a fool i was to actually think that this could be good instead i watched in disgust as poor acting stereotypes ripped of the storyline and script from the 1st one.<br /><br />Whoever thought that this straight-to-video production was actually even a half decent film you must be on crackd or something because I think what pretty much most of the people who've seen this film thinks WHAT A LOAD OF CRAP!!!!\"\n",
            " b'I had to shut this off after about 15 execrable moments..<br /><br />I was hoping it might improve,<br /><br />What I saw was badly acted, directed & written.<br /><br />This movie should never even have been released directly to DVD,.<br /><br />The lead character who is a bride top be from HELL has an huge Ice sculpture fall on her killing her. She was such a revolting person I was not even sorry for her. She winds up there in a sort of heaven, & was still repulsive, I left shortly after.<br /><br />Eve Longoria portrays her & I hope I never see her again, she cant even act.She is just plain annoying.<br /><br />Paul Rudd an actor who normally can do no wrong also was in this dud.<br /><br />Jason Biggs ( no longer a teen) is also present,<br /><br />I do like comedies BUT not stupid ones about stupid people.<br /><br />Rating: * (out of 4) 30 points (out of 100) IMDb 2 (out of 10)'\n",
            " b\"I saw this a couple of nights back, not expecting too much and unsurprisingly it didn't deliver anything too exciting. The plot set up of a crew of vampire hunters (V-San, for vampire sanitation), going around in their spaceship periodically killing space vamps and rescuing people, is quite sound and had the film been handled better it might well have been something quite ace. Unfortunately after a fairly decent opening the sense of actual quality starts to drain away from the film, leaving something behind that, though vacantly watchable, is quite laughably bad. I don't expect anything too special from these films that pop up on the Sci Fi Channel and at least this wasn't one of their creature features with an atrocious cgi beast shambling about, but it was still pretty bad, mostly due to the writing and acting, but with a sterling contribution to the overall badness made by the horrible music. When the film opted just for a typical science fiction sounding weird noises approach to the soundtrack it did OK, but all too often hilariously bad soft rock intruded and pitched scenes into silliness. I would have tolerated the general cheesy acting and writing more were it not for the choice of music, which was a serious miscalculation, turning things from cheesy to lamely comical. Of the acting, Dominic Zamprogna was OK but bland as the nominal hero, whilst Leanne Adachi was pretty irritating as the tough girl of the vamp busting team and Aaron Pearl played another member who wasn't well written or interesting enough to make an impression. Though she didn't seem that good at the acting lark Natassia Malte did well through having a less irritating character than the others, and the fact that she is seriously nice to look at. The only serious name in the cast is Michael Ironside and he is underused though he does nicely, pretty amusing in a manner one suspects was intentional. He seems to have fun and earn his paycheck and his role is entertaining. The effects are OK on the whole, they are at least of the standards of the average science fiction TV show, and there are also a few scenes of blood splatter and a bit of fun gore as well. Things move along nicely, and I almost feel harsh rating this film badly, but then I remember bursting into laughter at regular intervals and realising that unless the film is an intentional comedy, which I don't think it is, then it simply doesn't succeed. Too much is lame, daft, unconvincing, its an OK effort I guess but it didn't appeal to me. Only give it a go if you really dig Sci Fi trash or unintended chuckles I'd say.\"\n",
            " b'It really is that bad of a movie. My buddy rented it because he, well, is an idiot. But then again, I must be an idiot too because I watched the whole damn thing! The actors were on par with high school drama geeks who think that are going places. The only place they will be going is back to waiting tables at Luby\\'s. All I could think of while I was watching this \"gem\" was how it actually got made. I mean, some \"screenwriter\" actually thought that this premise was fresh, original and lucrative. Then some moron with money believed in the script so much that he decided to fork some cash over with the naive misconception that he was going to make a return on it. Actors were cast, locations were scouted, make-up artists were hired, computer animators fresh out of Al Collins graphic Design School were brought in and this turd started to take form.<br /><br />There obviously were a ton of things that I hated about this move but the one thing the drove me the craziest was the overuse of music. Every single minute of this flick was scored. There was not a single break in music. And at times it was mixed higher than the dialogue, not that it made you miss some vital plot point or anything.<br /><br />After it was over, we decided to watch Mystic River. It was like driving a 1980 VW Diesel Rabbit then switching to a BMW 740il. You couldn\\'t get two more opposite movies in terms of quality.'\n",
            " b'My wife did not realize what a gem this movie was when she picked it up. It is a story that shows real world success through hard work and determination.<br /><br />That is so refreshing in a world of violent movies not that I dis-like them), but you have to love a movie that succeeds without it.'\n",
            " b\"I cant believe blockbuster carries this movie. It was SO BAD. I was totally fooled by the box art. DON'T BE FOOLED!! Its not worth your time I promise you. I don't know if the positive reviews for this flick were a joke or what. I am so disappointed. :( <br /><br />The description on the back of the box doesn't even match! The girl that has the voodoo done on her is a stripper. The synopsis on the back says she is only 17. Did the people writing the description for the film even bother to watch it!? Those positive reviews had to be a joke they just had to be. If anyone actually liked this flick then I've lost all faith in humanity.<br /><br />And don't even get me started on the story compared to the title. Or the fact that the entire movie was done all in 2 locations. Or that the cops didn't even have close to real uniforms. Why would i even say that?? Who cares about the cops uniforms!? Compared to the rest of the movie the uniforms were spot on. <br /><br />This movie is an insult to the zombie genre and all of its fans.\"\n",
            " b'You may say to yourself, \"Don Johnson as Elvis? Can that work? Is it possible? Seems like an terrible choice to me, but perhaps I should have an open mind. Maybe I\\'ll be surprised. Maybe he can pull it off.\"<br /><br />NOT!<br /><br />Don Johnson is not a bad actor. But he is an awful Elvis. He\\'s too short, too weak-voiced, too sharply featured ... well you\\'ve already imagined how bad he would be. Add to that a hokey black wig and heavy-handed eye-liner and mascara and it\\'s a big fat embarrassing mess.<br /><br />The best I can say is that since Johnson\\'s acting is decent and since his impersonation is so far off, after a while you don\\'t even think of him as Elvis anymore. You see him as some other crazed pop star instead. Then, on that level, the movie becomes watchable.<br /><br />Stephanie Zimbalist is also not ideally cast as the tall, beauty queen, Linda Thompson. But she is attractive in her own right and plays the part with the honesty, elegance and intelligence we\\'ve come to expect from all her roles. There may be too much intelligence in her performance. You have to be kind of a dope to stick with a dope abusing dope.<br /><br />There\\'s nothing new to this story; we\\'ve heard it many times before. If you\\'ve looking for new info or insight, you won\\'t find it. It\\'s told as a love story - an unrequited one: Linda for Elvis and Elvis for drugs.'\n",
            " b\"Dark comedy? Gallows humor? How does one make a comedy out of murder? It can be risky business as the viewer is required to let go of their moral values and laugh at the antics of a man who kills people. So, the story has be rock solid with a good dash of suspended reality in order to make it work. So, Pierce Brosnan, the Irishman's answer to 007 is now cast as a chain-smoking, sex-addicted alcoholic who kills people for a living and is having a life crisis. He meets a struggling businessman, Greg Kinnear, and after a rocky beginning, he learns that he needs a friend. But, Greg's happily married to Hope Davis and Brosnan sees in him the basic things he doesn't have, love, home and a life. Add character actor, Philip Baker Hall as the hit-man's manager and we're off to the races. Brosnan is wonderfully crass and crude as the anti-hero and Kinnear delightful as his counterpart, the very human businessman. Hope Davis adds a sparkle as Kinnear's very conventional wife who is fascinated with this derelict who drifts into their lives. The ending is delightful and with some surprise to it. You should leave the theater feeling, at least, partly good-- if you're able to suspend being aghast at killing people.\"\n",
            " b\"A good Korean film about not just Taekwondo but what its takes to be good, like a thugs way of fighting cannot beat a taekwondo guy in his sport because there are rules, just as there are to life and school and this film has undertones of this notion.<br /><br />The martial arts in the film isn't that good but it is passable and enjoyable. Friends who go on to achieve something they once would mock become stronger through the mind and heart. This film isn't meant to be taken too seriously as it does have slapstick, but it also carries a message.<br /><br />A good film again from Korea.\"\n",
            " b\"I saw a special advance screening of this today. I have to let you know, I'm not a huge fan of either Dane Cook or Steve Carell, so I really had no expectations going into this. I ended up enjoying it quite a bit.<br /><br />Dan in Real Life is the story of a widower with 3 daughters who goes to spend a weekend with his family. While at a bookstore, he meets the woman of his dreams, only to find out that she happens to be his brother's girlfriend.<br /><br />This movie is pretty well made- the soundtrack, cinematography, and acting are all top-notch, especially Steve Carell. My problem with it was mostly that there seemed to be a lack of character development, mostly with Dane Cook's character. We never really get a close look at the relationship between Dane and Steve's characters, and I felt that it could have helped a bit in showing what Dan's inner conflict about being in love with Dane's girlfriend was like. Other than this though, Dan in Real Life is definitely a solid, sweet film- definitely a nice break from all the horror and action movies we've been getting this year.\"\n",
            " b\"As I sat subjected to this televised mediocrity, I wondered why? Why did Dianne Keaton agree to this trash? The movie uses meaningless, contrived plot lines to deliver trash to homes of thousands. The movie takes a political agenda to a new level. The movie was meaningless, and all creditability was lost to the excessive use of stereotype. <br /><br />It was obvious that Keaton tried to make this movie worthwhile, but in the end she needs to remember the age old adage that you cannot polish a turd. I hope that you did not waste your New Year's Day watching another mindless made for TV movie. I now know why the networks started airing series on Sunday night, to rid us of trash!\"\n",
            " b'<br /><br />This movie sucks. Ridiculous \"school\" athmosphere, unbelievable students that are very bad and behave like criminals but then later after the \"good teacher\" Nick Nolte taught them they became as good and as quiet as kittens.<br /><br />If this works for you, it doesn\\'t for me. 0 out of 10'\n",
            " b\"First off, this really is my favorite film ever. I don't need to give anyone a description because every a**hole does that. I am literally obsessed with this practically bloodless, cheesy, lame effects having', boom-stick showing', badly edited, 80's metal horror masterpiece. The director (I heard) had hoped for a hit at the box office so that he could do sequels and have a FREDDY/JASON type of deal for himself. Damn, I wish that could've went down like that! The soundtrack's banging'. The acting's good....CHECK THIS MOFO OUT. and any die-hard fans out there, feel free to email and chat sometime. Midgetorgy....I can be found at YAHOO.\"\n",
            " b\"The idea behind this film was a good one. Too bad it wasn't written well. Casting Sidney Poitier as the FBI agent was a good idea, and he did an outstanding job. Tom Berenger, on the other hand, only knows one emotion in most of his movies, anger. Kirstie Alley's character could have been a great one, and even showed some possibilities once, but the writer really let us down by making her role mostly a helpless female. This was completely inconsistent with the strongly independent character she was supposed to be. I don't care for Alley's acting anyway. The movie should have ended about fifteen minutes sooner than it did. The director milked the cow dry before the unbelievable final action. I will keep this in my collection only as an example of Poitier's performances.\"\n",
            " b\"No matter how you look at this movie, it is just awful.<br /><br />If you view it as a horror, then it is an unscary movie with the monsters being hand puppets.<br /><br />If you look at it as a comedy, then you will notice most of the humor falls flat and is just lame.<br /><br />If it is a romance you will wonder why a guy would stay with such a B**ch!<br /><br />If you look at it as an action you can't really pull for the whiny hero.<br /><br />As you can see this movie just fails to deliver anything remotely entertaining. As mentioned the monsters are obvious puppets and this film was another attempt at a Gremlins type movie. This however has the worst looking monsters of that genre. Critters looked pretty good, so did the Ghoulies, heck even the puppets from the Munchies looked better than these. The characters in this film are thouroughly unlikable. The hero is a whiney security guard, his girlfriend is always complaining, they have a tramp friend who has a jerk military boyfriend, and another friend who is a spaz. At one point in the movie the hero and the military guy fight with rakes...this movie is just utterly stupid. I like the scene when they are in the dreaded club scum (which is obviously not a club, but more likely a diner) and the hero tells the waitress that none of them are 21. Give me a break, I am 25 and I look younger than any of them.\"\n",
            " b'You know all those letters to \"Father Christmas\" and \"Jesus\" that are sent every year? Well, it turns out that they are not actually delivered but dropped off in a half-forgotten corner of the post office to rot unless some bright spark figures out a way of posting them. As bizarre settings go, it\\'s a winner and one which perfectly fits the strange movie that is \"Dead Letter Office\". Having said that, this is obviously an Australian film as opposed to a British one. If it was Royal Mail, most letters get this sort of treatment anyway. I haven\\'t been in this flat for two years and we\\'re still getting letters for a Mr Wang, some female priest of the Church of Latter Day I\\'ve-Never-Heard-Of-You and various catalogues for industrial equipment addressed to a plumbing company.<br /><br />\"Dead Letter Office\" (the name given to the place where undeliverable mail ends up) follows the story of Alice (Miranda Otto) who grows up in a seriously divided home. Writing to her absent father, she only learns in adulthood that her letters haven\\'t been delivered for one reason or another. So, logically, she gets a job at the D.L.O. and finds herself working alongside other social rejects including the brooding Chilean immigrant Frank Lopez (George Del Hoyo). Slowly, she finds herself drawn to him but can she find out where her dad is without bringing the self-contained world of the Dead Letters Office to its knees?<br /><br />Nothing against this film but I was reminded of the god-awful Heather Graham film \"Committed\" while watching this. However, this is so much better than that pile of horse crap but then again, that ain\\'t difficult. For a start, this film is much more logical. True, the metaphors are somewhat blatant and the underflowing symbolism quickly becomes a flood. But at least this is cohesive and quirky without being complete drivel. It is also well acted. Both Otto and Del Hoyo are very good as the lovers looking for something they know they\\'ll never find while other characters are peripheral at best. Part of the trouble is that it seems to wrap up far too quickly, leaving this viewer somewhat disappointed. The other part is that when you consider Australia\\'s draconian immigration policy (i.e. if you don\\'t speak English, rack off!), such a story is unlikely to take place in reality. The other characters, sadly, also help to destabilise the realism by proving to be little more than odd-ball stereotypes.<br /><br />Despite that, \"Dead Letter Office\" is certainly something a little different. It might not be to everyone\\'s taste but I liked it. Yes, it was hackneyed and predictable but sometimes, it\\'s nice to watch a film without guns or violence or heavy-duty swearing and nudity (no chance of that in an Australian film). There ain\\'t any major laughs, there\\'s no Bullet Time and the characters are usually one-dimensional. But it\\'s the story that counts here and while it\\'s not earth-shattering in its magnificence, it\\'s a pleasant enough way of passing the time. It\\'s the movie equivalent of a Sheryl Crow CD - nice to listen to now and again but you wouldn\\'t really miss it if it wasn\\'t there.'\n",
            " b'Mary Tyler Moore and Valerie Harper still can turn the world on with their smiles. The combined talent of these two wonderful stars make this combination reunion/newstart movie work. Watch it and look forward to hitting sixty! Mary defies the youth oriented society with wit and charm. A touch of drama adds 2000 realism. A TV series follow up would broaden the new characters and give us a chance to occaisionally see Lou Grant, Phyllis, Sue Ann, Murray, and Georgette!'\n",
            " b\"Harvey Keital's best performance so far the new century. Very nicely photographed, a beautiful snap-shot of pre-Castro Cuba. The story revolves around the nephew of a local minor crime boss who develops a friendship with an American with Hollywood connections. It's really about the moment when a boy awakens to the fact that the small circle of people he knows actually live in a much larger, much more complex world that he doesn't yet understand.the script is strong and filled with humor, the direction is crisp. Over all, a really professional job that fits in well with the tradition of Latin American cinema. The one weakness is the decision to shoot in sync-sound English rather than Spanish - probably to improve sales in the US. Unfortunately, this just makes the film a little less convincing. But if you can see beyond this, you will find a heartfelt trip to another world. Recommended.\"\n",
            " b'First saw this half a lifetime ago on a black-and-white TV in a small Samoan village and thought it was hilarious. Now, having seen it for the second time, so much later, I don\\'t find it hilarious. I don\\'t find ANYTHING hilarious anymore. But this is a witty and light-hearted comedy that moves along quickly without stumbling and I thoroughly enjoyed it.<br /><br />It\\'s 1945 and Fred MacMurray is a 4F who\\'s dying to get into one of the armed forces. He rubs a lamp in the scrapyard he\\'s managing and a genie appears to grant him a few wishes. (Ho hum, right? But though the introduction is no more than okay, the fantasies are pretty lively.) MacMurray tells the genie that he wants to be in the army. Poof, and he is marching along with Washington\\'s soldiers into a particularly warm and inviting USO where June Haver and Joan Leslie are wearing lots of lace doilies or whatever they are, and lavender wigs. Washington sends MacMurray to spy on the enemy -- red-coating, German-speaking Hessians, not Brits. The Hessians are jammed into a Bierstube and singing a very amusing drinking song extolling the virtues of the Vaterland, \"where the white wine is winier/ and the Rhine water\\'s Rhinier/ and the bratwurst is mellower/ and the yellow hair is yellower/ and the Frauleins are jucier/ and the goose steps are goosier.\" Something like that. The characterizations are fabulous, as good as Sig Rumann\\'s best. Otto Preminger is the suspicious and sinister Hessian general. \"You know, Heidelberg, vee are 241 to 1 against you -- but vee are not afraid.\" <br /><br />I can\\'t go on too long with these fantasies but they\\'re all quite funny, and so are the lyrics. When he wishes he were in the Navy, MacMurray winds up with Columbus and the fantasy is presented as grand opera. \"Don\\'t you know that sailing west meant/ a terrifically expensive investment?/ And who do you suppose provides the means/ but Isabella, Queen of Queens.\" When they sight the New World, someone remarks that it looks great. \"I don\\'t care what it looks like,\" mutters Columbus, \"but that place is going to be called Columbusland.\"<br /><br />Anyway, everything is finally straightened out, though the genie by this time is quite drunk, and MacMurray winds up in the Marine Corps with the right girl.<br /><br />I\\'ve made it sound too cute, maybe, but it IS cute. The kids will enjoy the puffs of smoke and the magic and the corny love story. The adults will get a kick out of the more challenging elements of the story (who are the Hessians?) unless they happen to be college graduates, in which case they might want to stick with the legerdemain and say, \"Wow! Awesome!\"'\n",
            " b'A stupid young man becomes obsessed with a woman--so obsessed that he loses perspective and common sense. An evil magician approaches him and informs him he can give him great wealth that he can use to win the lady\\'s heart IF he agrees to give him anything he wants that\\'s within their room. The dumb guy agrees and the magician steals the man\\'s reflection out of the mirror--and bad things naturally occur as a result.<br /><br />If this film had been made just a decade later, I am sure I wouldn\\'t have been so charitable in reviewing and scoring this film. After all, the film\\'s plot is a bit vague in spots and the acting is, at times, a bit stilted. However, when you consider that in 1913 \"full-length\" films were rare--and often only 20 to 30 minutes long! Plus, the whole idea of a complex story like you get in this film is very unusual--as stories were very short and broadly acted. So, given the limitations of the time, this film is pretty good and is one of the earlier horror films known.'\n",
            " b'While many unfortunately passed on, the ballroom scene is still very much alive and carrying on their legacy. Some are still very much alive and quite well, Octavia is more radiant and beautiful than ever, Willi Ninja is very accomplished and gives a great deal of support to the gay community as a whole, Pepper Labeija just passed on last year of natural cause, may she rest in peace. After Anji\\'s passing Carmen became the mother of the house of Xtravaganza (she was in the beach scene) and she is looking more and more lovely as well. Some balls have categories dedicated to those who have passed, may they all rest in peace. There is currently another project underway known as \"How Do I Look?\", you can check out the website at www.howdoilooknyc.org.'\n",
            " b\"Vincent Price's follow-up to HOUSE OF WAX (1953), the film which cemented his reputation as a horror icon, similarly revolves around a bitter \\xc2\\x96 albeit resourceful \\xc2\\x96 showman. Though a remake, the former (shot in Technicolor) remains the superior effort; that said, apart from some resistible comic relief, the obligatory resort to cheap gimmickry (it was another 3-D showcase) and occasional narrative shortcomings (whatever happened to the missing bag which supposedly turned up at some police station containing a severed head?), this offers more than enough Grand Guignol-type thrills and overall camp value (Price hamming it up in a variety of disguises as an inventor of illusions impersonating 'missing' star conjurers who had taken advantage of his genius) to stand on its own two feet. Incidentally, director Brahm's involvement here proves no mere coincidence \\xc2\\x96 since the narrative incorporates elements from two horror titles (both starring Laird Cregar) he had previously helmed i.e. THE LODGER (1944) and HANGOVER SQUARE (1945). The young leads are played by Mary Murphy (as Price's ing\\xc3\\xa9nue assistant) and Patrick O'Neal (as her police detective boyfriend \\xc2\\x96 curiously enough, he would himself take the lead in a similar piece, CHAMBER OF HORRORS [1966], which I have acquired just in time to serve as an encore to this one). An interesting sideline here is the latter's adoption of a novel detection technique, fingerprinting, which is crucial in bringing about Price's downfall (in a predictable but rather awkward fiery climax)\\xc2\\x85though the persistent snooping of his amateur crime novelist landlady has at least as much to do with it in the long run! Watching the star in a made-to-measure role, the film emerges a good deal of fun \\xc2\\x96 particularly at a compact 73 minutes.\"\n",
            " b\"not your typical vamp story, not bram stoker or anne rice here. a truly original vampyre story. these vampyres are genetic mutants who the sunlight don't bother. they are pure evil to. <br /><br />the film is not perfect. many of the actors are clearly amateurs. the two leads who play van helsing and rally the vampyre chick are pretty good though. the film is intensely violent which may disturb some people. also it is loaded with scientific detail that many will find hard to understand and may get bored with. i was sold on the clever storyline and the couple good performances. no telling how successful this film could be if they had a bigger budget and it got mass distribution\"\n",
            " b'Joseph Brady and Clarence Doolittle are two sailors, who have a four-day shore leave in Hollywood.Joe knows everything about girls and can\\'t wait to see Lola, while Clarence is shyer and needs some advice from his buddy on how to meet girls.They then run into a little boy, Donald Martin, who has ran away in order to join the navy.They take him home and meet his beautiful aunt Susan, who wants to be a singer.Clarence wants Susie to be his girl, but his shyness gets in the way.But he doesn\\'t feel shy with a waitress, who comes from Brooklyn, like he does.Soon Joe notices he\\'s in love with Susie.The boys are in a fix when they lie to Susie on meeting with a big time music producer they don\\'t even know.As they are in a fix with their feelings.George Sidney\\'s Anchors Aweigh (1945) is a great musical comedy.Gene Kelly is top-notch, once again, in his singing and dancing routines.Frank Sinatra is terrific as the shy guy from Brooklyn.Shy isn\\'t the first thing that comes to mind when you think of Frank Sinatra, but he plays his part well.Kathryn Grayson is fantastic as Susan Abbott.We sadly lost this gifted actress and operatic soprano singer last month at the age of 88.The 9-year old Dean Stockwell does amazing job as the little fellow wanting to become a sailor.Jose Iturbi does great job performing himself.It\\'s magic what he does with the piano.Edgar Kennedy plays Chief of police station.Sara Berner is the voice of Jerry Mouse.There\\'s a lot of great stuff in this movie and some fantastic singing and dancing numbers.Just look at Kelly and Sinatra performing \"We Hate to Leave\".It\\'s so energetic.\"If You Knew Susie (Like I Know Susie)\" is quite funny.It\\'s a nice moment when Frank sings Brahms\\' Lullaby to little Dean Stockwell.It\\'s lovely to listen to Grayson singing the tango \"Jealousy\" .The most memorable sequence is the one that takes into the animated fantasy world, and there Gene sings and dances with Jerry Mouse.Also Tom Cat is seen there as the butler.They originally asked Mickey Mouse but he refused.The movie was nominated for five Oscars but Georgie Stoll got one for Original Music Score.Anchors Aweigh is some high class entertainment.'\n",
            " b'Holy @#%& this movie was still warm and juicy from the pile it was made with. I tried to watch this pile of festering waste but found it easier to slash my wrists and slug back a shooter of Lysol floor cleaner than endure more than half of the crap that was on my screen. I rank this well below anything I have ever watched on film or TV, and thats saying something. I once witnessed a cow crap in a field. I watched the steaming pile for a hour and a half, who knows... it might have moved or something. Well that was time better spent than watching this tripe. The acting was non-existent, the plot was somewhere other than on this film. I think I saw a cut seen early on where the plot managed to escape and was riding off in the background on the back of a old pickup truck heading to Portland in hopes of becoming a Steven King shi77er. Please tell me director is getting medication he so desperately needs. It\\'s pretty clear he needs heavy medication and I\\'d willing to front the money needed for his lobotomy reversal. Bah... I can\\'t give this review the full punch it needs because nothing this painful can ever be done justice in typed word alone. Let me just say that if your looking for a flick to pass some time and you see this Chilton on the rack, walk to your car, start the engine, then shove both of your fists straight into the fan until it you can\\'t feel your bones vibrate anymore. Be sure to have your wallet in hand also because you were going to waste the cash anyway. You might as well have the privilege of wasting it yourself.<br /><br />By the way, I watched this after a \"buddy\" of mine sent his girlfriend over so I could see it. HE dint come over, SHE had too. Whats worse is that she had to watch this $%&@ thing TWICE! I heard their married now and he gets to visit his balls once a month. I hope it was because of this film.'\n",
            " b\"Oh, where are you going, my little one, little one...<br /><br />Turn around and you're two, turn around and you're four...<br /><br />I remember these shows when they were first broadcast on Disneyland. I remember sitting there, electrified by Werner Van Braune's explanations of rocket science. I watched as history, science and humor were all interwoven in an engrossing story of possibilities.<br /><br />That was fifty years ago. And the shows are back in the Disney Treasures series, and what a treasure they are. I watched them last night and tonight with my 8 year old daughter, who at first would not even come in the room, but later changed her mind when she saw they were partly animated. As she watched I watched her, and by the end she was nearly as engrossed as I had been.<br /><br />Turn around and you're a young wife with babes of your own...<br /><br />Sure, some of the predictions about reaching the moon were wrong. But there is a lot of information that is still quite accurate, and the overall presentation is still impressive. I found myself thinking my daughter's teacher might want to show them to her class, not only as a 50 year old artifact, but also as fun and easy to understand lessons in history.<br /><br />Turn around, turn around, turn around and again...you're wondering how much has really changed in 50 years.\"\n",
            " b'<br /><br />Charlie Kauffman has made weird metaphysical angst popular, but this canadian gem makes it hilarious. <br /><br />Like most weird films the less said about plot the better but let\\'s set the scene, two friends Anthony and Dave have been together since childhood, they can\\'t cope with the world and eventually this means they no longer have to. But that is where even more problems begin.<br /><br />I loved this film, it made me smile long after the final credits and that is a rare experience with so many mass produced pieces of \"nothing\" out there.<br /><br />Don\\'t miss this.<br /><br />'\n",
            " b\"When I go to see a movie about zombie's, I'm not expecting oscar calibre performances, or writing on the level of The Godfather, but I do expect the actors to at least not look like their straining to read their cue cards, and dialogue that doesn't sound like it was typed out 10 minutes before the actor reads it into the camera. This movie was just awful, I actually got up and left about 25 minutes in and went next door and watched Cold Creek Manor, that wasn't very good either, but it seemed like Citizen Kane compared to this pile of crap. On the plus side, the girls were very pretty, that's probably the only thing that kept me in my seat for longer than the first 5 minutes, in fact I left after the hottest one got killed, there wasn't anything to hold my interest after that.\"\n",
            " b'That\\'s a snippet of choice dialogue delivered by the evil, ballbusting lady assistant of a famous scientist to her prim maid just before she lures three incredibly dumb college girls to a mansion for behavior modification experiments. Meanwhile, at the local bar, people drink and dance to lame 80s rock songs. A biker punk has sex with a cycle slut on a pinball table in front of a crowd of people, then tries to rape the scientist\\'s virginal daughter Jessica (Debra Hunter), who is in love with another biker (Dale Midkiff, from PET SEMATARY), who, in turn, is in cohorts with the assistant! Back at the house, the sorority bimbos swim, shower, change clothes and have sex with men from the bar. A small silver ball (part of the experiment) flies into victims mouths and turns them into drooling, killer zombies!<br /><br />If that isn\\'t enough to entertain you, there\\'s a hilarious theme song (\"Nightmare Fantasy\"), roller skating, some serious daisy dukes and a psychic hand puppet (!?) that warns \"DANGER! DANGER!\" just like the LOST IN SPACE robot and recommends hitchhiking as one of the best ways to pick up men!<br /><br />This filmed-in-Florida mess is so mind-numbingly awful that multiple viewings are recommended to soak it all in. And, hey isn\\'t that NYPD Blue\\'s Detective Jill Kirkendall turned CNN newscaster Andrea Thompson as one of oft-nude bimbos? Sure is! Supposedly this was started in 1982 and new footage was added later for the video release in 1985.<br /><br />Score: 1 out of 10 (and I mean that in a good way!)'\n",
            " b\"I caught this movie late at night on cable, and I was pleasantly surprised. I can only imagine the reason this movie was not better known, is because the subject matter is very disturbing. But if you can handle the sexual abuse topic, it is a well acted, suspenseful and very interesting movie. Both Richard Gere and Claire Daines are very good in it. And although the subject matter is not for the faint of heart, the movie doesn't go out of its way to be brutal either (like 8mm for instance).<br /><br />I highly recommend it to anyone who enjoys serial killer and suspense type movies.\"], shape=(32,), dtype=string)\n",
            "tf.Tensor([1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1], shape=(32,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F_kPfyorF7n"
      },
      "source": [
        "**Inspecting the output of our binary unigram dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRlAxC9irF7n",
        "outputId": "358635b2-21a0-4ab7-9214-235893367fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'float32'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWNyePi0rF7n"
      },
      "source": [
        "**Our model-building utility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2HxSMAZXrF7o"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54O7t-qsrF7o"
      },
      "source": [
        "**Training and testing the binary unigram(uni=1) model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMAYlIk1rF7o",
        "outputId": "308d541e-ddcc-4413-c367-3ac3f6090316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 13s 19ms/step - loss: 0.4087 - accuracy: 0.8287 - val_loss: 0.3066 - val_accuracy: 0.8810\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2758 - accuracy: 0.8948 - val_loss: 0.3021 - val_accuracy: 0.8844\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2494 - accuracy: 0.9125 - val_loss: 0.3280 - val_accuracy: 0.8814\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2301 - accuracy: 0.9211 - val_loss: 0.3296 - val_accuracy: 0.8842\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2268 - accuracy: 0.9240 - val_loss: 0.3427 - val_accuracy: 0.8834\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2213 - accuracy: 0.9277 - val_loss: 0.3863 - val_accuracy: 0.8818\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2136 - accuracy: 0.9308 - val_loss: 0.3664 - val_accuracy: 0.8850\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2183 - accuracy: 0.9341 - val_loss: 0.3673 - val_accuracy: 0.8872\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.2070 - accuracy: 0.9347 - val_loss: 0.3690 - val_accuracy: 0.8824\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.2119 - accuracy: 0.9359 - val_loss: 0.3768 - val_accuracy: 0.8854\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.2910 - accuracy: 0.8887\n",
            "Test acc: 0.889\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDEnUhsrF7o"
      },
      "source": [
        "#### Bigrams with binary encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHo5gWAqrF7o"
      },
      "source": [
        "**Configuring the `TextVectorization` layer to return bigrams**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NqL_Z995rF7o"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9UR9kQ0rF7p"
      },
      "source": [
        "**Training and testing the binary bigram model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "gOhraBwGyNzN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_vocabulary()"
      ],
      "metadata": {
        "id": "bV3cBSwxyPoU",
        "outputId": "cbe58e82-16e8-416b-af01-3239f1e32d03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_vectorization.get_vocabulary())"
      ],
      "metadata": {
        "id": "tMHXQSxYyTvQ",
        "outputId": "e7c0ea0f-e6c5-4fbb-a3cd-dff56291dffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cRZtVdYrF7p"
      },
      "outputs": [],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaVaSqbUrF7p"
      },
      "source": [
        "#### Bigrams with TF-IDF encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzb2zqL-rF7p"
      },
      "source": [
        "**Configuring the `TextVectorization` layer to return token counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU1fs8r5rF7p"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"count\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1K8cvlerF7q"
      },
      "source": [
        "**Configuring `TextVectorization` to return TF-IDF-weighted outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URO0tXjXrF7q"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"tf_idf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPIJFSpXrF7q"
      },
      "source": [
        "**Training and testing the TF-IDF bigram model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOk_PyHlrF7q"
      },
      "outputs": [],
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(tfidf_2gram_train_ds.cache(),\n",
        "          validation_data=tfidf_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv5zEjkHrF7q"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "processed_inputs = text_vectorization(inputs)\n",
        "outputs = model(processed_inputs)\n",
        "inference_model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRq4vKK1rF7r"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "raw_text_data = tf.convert_to_tensor([\n",
        "    [\"That was an excellent movie, I loved it.\"],\n",
        "])\n",
        "predictions = inference_model(raw_text_data)\n",
        "print(f\"{float(predictions[0] * 100):.2f} percent positive\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chapter11_part01_introduction.i",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}